{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Prepare data: extract, transform, load (ETL)\n",
    "###\n",
    "import h5py as h5\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "    \n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "RATE = 8192\n",
    "\n",
    "class GWInject():\n",
    "    def _shift_noise(self, tag, A, shift):\n",
    "        MAX=self.srate\n",
    "        var = self.f[tag]\n",
    "        NX = len(var)\n",
    "        \n",
    "        ## make shifted template first\n",
    "        swf = np.zeros(var.shape)\n",
    "        for i in range(NX):\n",
    "            a = int((np.random.random()-0.5)*shift)  ## shift left or right\n",
    "            swf[i,max(0,a):min(MAX, MAX+a)] += A * np.roll(var[i], a)[max(0,a):min(MAX, MAX+a)]\n",
    "            \n",
    "        NN = self._NOISE_COPY_*NX\n",
    "        noise = np.random.normal(0,1,(NN,self.srate))    \n",
    "        X     = np.random.normal(0,1,(NX,self.srate)) + A * swf[:NX,:]\n",
    "        X = np.vstack( (noise, X )    ).astype(np.float32)\n",
    "        Y = np.array([0]*NN + [1]*NX) .astype(np.int32).reshape(-1,1)   ## change float --> int\n",
    "        \n",
    "        if self.plot:\n",
    "            plt.figure(figsize=(16,5))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(3,5,i+1)\n",
    "                plt.plot(X[NX+i,:])\n",
    "                plt.plot(swf[i,:])\n",
    "                #plt.title(\" )\n",
    "                if (i > 13): break\n",
    "            plt.show()\n",
    "\n",
    "        return X, Y\n",
    "    def _add_noise(self, tag, A):\n",
    "        var = self.f[tag]\n",
    "        NN = self._NOISE_COPY_ * NX\n",
    "        NX = len(var)\n",
    "        noise = np.random.normal(0,1,(NN,self.srate))    \n",
    "        X     = np.random.normal(0,1,(NX,self.srate)) + A * var[:NX,:]\n",
    "        X = np.vstack( (noise, X )  ).astype(np.float32)\n",
    "        Y = np.array([0]*NN + [1]*NX).astype(np.int32).reshape(-1,1)\n",
    "        \n",
    "        if self.plot:\n",
    "            plt.figure(figsize=(16,5))\n",
    "            for i in range(len(X)):\n",
    "                plt.subplot(3,5,i+1)\n",
    "                plt.plot(X[i,:])\n",
    "                plt.plot(A * var[i,:])\n",
    "                #plt.title(\" )\n",
    "                if (i > 13): break\n",
    "            plt.show()\n",
    "\n",
    "        return X, Y\n",
    "    def __init__(self, fname, plot=0):\n",
    "        self.fname = fname\n",
    "        self.plot = plot\n",
    "        self.f = h5.File(fname, \"r\")\n",
    "        self.srate = self.f.attrs.get('srate')\n",
    "        self._NOISE_COPY_ = 6\n",
    "        \n",
    "    def __exit__(self):\n",
    "        self.f.close()\n",
    "        \n",
    "    def get_train_set(self, A=1.0):\n",
    "        return self._add_noise('/train_hp', A)\n",
    "    \n",
    "    def get_test_set(self, A=1.0):\n",
    "        return self._add_noise('/test_hp', A)\n",
    "    \n",
    "    def get_val_set(self, A=1.0):\n",
    "        return self._add_noise('/val_hp', A)\n",
    "\n",
    "    def get_shifted_train_set(self, A=1.0, shift=0):\n",
    "        return self._shift_noise('/train_hp', A, shift)\n",
    "\n",
    "    def get_shifted_test_set(self, A=1.0, shift=0):\n",
    "        return self._shift_noise('/test_hp', A, shift)\n",
    "    \n",
    "    def get_shifted_val_set(self, A=1.0, shift=0):\n",
    "        return self._shift_noise('/val_hp', A, shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Prepare NN model: small model\n",
    "###\n",
    "def model(x_, keep_prob, WIDTH):\n",
    "    feature = tf.reshape(x_, [-1, WIDTH,1])\n",
    "\n",
    "    args = {\"padding\":'valid', \"activation\":None,\n",
    "            \"kernel_initializer\":tf.truncated_normal_initializer(), \n",
    "            \"bias_initializer\":tf.zeros_initializer()     }\n",
    "    \n",
    "    def convl(in_, F, K, D, S, PO, PS, act):\n",
    "        out = tf.layers.conv1d( in_, filters=F, kernel_size=K, dilation_rate=D, strides=S, **args)\n",
    "        out = tf.layers.max_pooling1d(out, pool_size=PO, strides=PS, padding='valid')\n",
    "        return act(out)\n",
    "        \n",
    "    o1 = convl(feature, F=16, K=16, D=1, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    o2 = convl(o1,      F=32, K=8,  D=4, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    o3 = convl(o2,      F=64, K=8,  D=4, S=1, PO=4, PS=4, act=tf.nn.relu)\n",
    "    \n",
    "    dim = o3.get_shape().as_list()\n",
    "    fcnn = dim[1]*dim[2]\n",
    "    o4 = tf.reshape(o3, [-1, fcnn])\n",
    "    o4     = tf.layers.dense(o4, 64, activation=tf.nn.relu, name=\"fc\")\n",
    "    logits = tf.layers.dense(o4, 2, activation=None)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "###  Construct TF graph\n",
    "###\n",
    "tf.reset_default_graph()\n",
    "DIM   = 8192\n",
    "LRATE = 1e-3\n",
    "keep_prob = tf.placeholder(tf.float32)   ##  for dropout, not used.\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,DIM])\n",
    "y = tf.placeholder(tf.int32, [None,1])\n",
    "\n",
    "logits = model(x, keep_prob, DIM)\n",
    "\n",
    "# Compute predictions\n",
    "#with tf.name_scope('eval'):\n",
    "##Never Used#predict_prob = tf.reshape(tf.nn.softmax(tf.reduce_max(logits,axis=1), name=\"softmax_tensor\"),[-1])\n",
    "predict_op = tf.argmax(input=logits, axis=1)   ##tf.reshape(tf.argmax(logits,axis=1),[-1])\n",
    "\n",
    "#with tf.name_scope('loss'):\n",
    "#loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.argmax(tf.cast(y, dtype=tf.int32),1)))\n",
    "loss_op = tf.losses.sparse_softmax_cross_entropy(logits=logits, labels=y) \n",
    "#print(loss_op)\n",
    "    \n",
    "#with tf.name_scope('optimizer'):\n",
    "optimizer = tf.train.AdamOptimizer(LRATE).minimize(loss_op)\n",
    "\n",
    "#_, accuracy    = tf.metrics.accuracy(labels=y, predictions=predict_op  )\n",
    "_, accuracy    = tf.metrics.accuracy(labels=y, predictions=predict_op  )\n",
    "_, sensitivity = tf.metrics.recall(labels=y, predictions=predict_op  )\n",
    "\n",
    "_, false_positives = tf.metrics.false_positives(labels=y, predictions=predict_op  )\n",
    "_, false_negatives = tf.metrics.false_negatives(labels=y, predictions=predict_op  )\n",
    "_, true_positives = tf.metrics.true_positives(labels=y, predictions=predict_op  )\n",
    "#_, true_negatives = tf.metrics.true_negatives(labels=tf.argmax(tf.cast(y, dtype=tf.int32),1), predictions=predict_op  )\n",
    "true_negatives = true_positives + false_negatives - false_positives\n",
    "tf.summary.histogram('loss', loss_op)\n",
    "tf.summary.scalar('loss', loss_op)\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning for A= 1.400000 , dataset size: 4795\n",
      "  Epoch:   0, loss:  1.99347e+02 acc: 0.477 sen: 0.997 sec:   2.1 speed:  2276.3 wf/sec\n",
      "  Epoch:   1, loss:  6.63555e-01 acc: 0.849 sen: 0.002 sec:   4.1 speed:  2308.6 wf/sec\n",
      "  Epoch:   2, loss:  6.40876e-01 acc: 0.856 sen: 0.002 sec:   6.1 speed:  2318.7 wf/sec\n",
      "  Epoch:   3, loss:  6.19841e-01 acc: 0.857 sen: 0.002 sec:   8.1 speed:  2326.4 wf/sec\n",
      "  Epoch:   4, loss:  6.00581e-01 acc: 0.858 sen: 0.002 sec:  10.1 speed:  2338.2 wf/sec\n",
      "  Epoch:   5, loss:  5.82712e-01 acc: 0.857 sen: 0.002 sec:  12.2 speed:  2328.1 wf/sec\n",
      "  Epoch:   6, loss:  5.66652e-01 acc: 0.857 sen: 0.002 sec:  14.2 speed:  2339.1 wf/sec\n",
      "  Epoch:   7, loss:  5.51701e-01 acc: 0.857 sen: 0.002 sec:  16.1 speed:  2347.7 wf/sec\n",
      "  Epoch:   8, loss:  5.38130e-01 acc: 0.857 sen: 0.002 sec:  18.1 speed:  2354.8 wf/sec\n",
      "  Epoch:   9, loss:  5.25903e-01 acc: 0.857 sen: 0.002 sec:  20.1 speed:  2357.6 wf/sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f7e2d48e2949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mrandomize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandomize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mrandomize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##\n",
    "##  Training with fixed template ....\n",
    "##\n",
    "    \n",
    "GWdata = GWInject(\"white_h_8192_dm2.h5\")\n",
    "\n",
    "BATCH = 128\n",
    "EPOCHS = 100\n",
    "MONITOR = 2\n",
    "\n",
    "PATIENCE = 4\n",
    "TOLERENCE = 1.e-7\n",
    "###\n",
    "ROOT_FOLDER = '/tmp/classifier-2'\n",
    "saver = tf.train.Saver(max_to_keep=50)\n",
    "\n",
    "TEST_LIST = [2.05, 2.0, 1.95, 1.9, 1.85, 1.8, 1.75, 1.7, 1.65, 1.6, 1.55, 1.5, 1.45, 1.4, 1.35, 1.3, 1.25, 1.2, 1.15, 1.1, 1.05, 1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
    "TRAIN_A = [2, 1.9, 1.8, 1.7, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 1, 0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "\n",
    "TRAIN_A = [1.4, 1.3, 1.2, 1.1, 1, 0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   \n",
    "    merged = tf.summary.merge_all()   ## call merged to do every summary\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for amp in TRAIN_A:\n",
    "        ## summarize to a new folder\n",
    "        train_writer = tf.summary.FileWriter(\"%s/train_%4.2f\" % (ROOT_FOLDER, amp ) )\n",
    "    \n",
    "        X_train, Y_train = GWdata.get_shifted_train_set(A=amp)\n",
    "        X_val,   Y_val   = GWdata.get_shifted_val_set(A=amp)\n",
    "        #X_train, Y_train = GWdata.get_train_set(A=amp)\n",
    "        #X_val,   Y_val   = GWdata.get_val_set(A=amp)\n",
    "        print(\"Trainning for A= %f , dataset size: %d\"% (amp, len(X_train) ))\n",
    "\n",
    "        patience = 0\n",
    "        \n",
    "        time0 = time.time()\n",
    "        for e in range(EPOCHS):\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "            randomize = np.arange(len(X_train))\n",
    "            np.random.shuffle(randomize)\n",
    "            X_train = X_train[randomize]\n",
    "            Y_train = Y_train[randomize]\n",
    "            randomize = np.arange(len(X_val))\n",
    "            np.random.shuffle(randomize)\n",
    "            X_val = X_val[randomize]\n",
    "            Y_val = Y_val[randomize]\n",
    "            STEPS   = int(len(X_train) / BATCH) \n",
    "            for i in range(STEPS):\n",
    "                xbatch = X_train[i*BATCH:(i+1)*BATCH, :]\n",
    "                ybatch = Y_train[i*BATCH:(i+1)*BATCH, :]\n",
    "                _, loss, summary = sess.run( [optimizer, loss_op, merged], feed_dict={ x:xbatch, y:ybatch }   ) \n",
    "                train_writer.add_summary(summary, global_step=e)\n",
    "            ### evaluate\n",
    "            loss, acc, sen = sess.run( [loss_op, accuracy, sensitivity],   feed_dict={x:X_val, y:Y_val} )\n",
    "            #loss, acc, sen = sess.run( [loss_op, accuracy, sensitivity],   feed_dict={x:X_train, y:Y_train} )\n",
    "            \n",
    "            duration = time.time() - time0\n",
    "            speed = STEPS * BATCH * (e+1) / duration\n",
    "            print('  Epoch: %3d, loss: %12.5e acc: %5.3g sen: %5.3f sec: %5.1f speed: %7.1f wf/sec' % (e, loss, acc, sen, duration, speed) )\n",
    " \n",
    "            if loss <  TOLERENCE:\n",
    "                if patience > PATIENCE: break\n",
    "                patience += 1\n",
    "            else:\n",
    "                patience = 0\n",
    "         \n",
    "        save_path = saver.save(sess, \"%s/model_%4.2f.ckpt\" % (ROOT_FOLDER, amp ) )\n",
    "        print(\"Model saved at %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Testing... with shift\n",
    "###\n",
    "BATCH = 4096\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    test_writer  = tf.summary.FileWriter(ROOT_FOLDER + '/test_hp')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    plt.figure()\n",
    "    for m in TRAIN_A:\n",
    "        try:\n",
    "            load_path = saver.restore(sess, \"%s/model_%4.2f.ckpt\" % (ROOT_FOLDER, m ) )\n",
    "            print(\"Model restored from %s\" % load_path )\n",
    "        except: \n",
    "            continue\n",
    "\n",
    "        gacc=[]\n",
    "        gsen=[]\n",
    "        \n",
    "        for amp in TEST_LIST:\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            \n",
    "            X_test, Y_test  = GWdata.get_shifted_test_set(A=amp, shift=2500)\n",
    "            randomize = np.arange(len(X_test))\n",
    "            np.random.shuffle(randomize)\n",
    "            X_test = X_test[randomize]\n",
    "            Y_test = Y_test[randomize]\n",
    "            \n",
    "            i=int(np.random.random()* int(len(X_test)/BATCH) )\n",
    "            xbatch = X_test[i*BATCH:(i+1)*BATCH, :]\n",
    "            ybatch = Y_test[i*BATCH:(i+1)*BATCH, :]\n",
    "\n",
    "            acc, sen, ttp, ttn, tfp, tfn = sess.run([accuracy, sensitivity, true_positives, true_negatives, false_positives, false_negatives ], feed_dict={ x: xbatch, y: ybatch })\n",
    "            gsen.append(sen)\n",
    "            gacc.append(acc)\n",
    "            print(\"Test for A= %4.2f : Acc: %9.3f, Sen: %9.3f, TP/TN/FP/FN: %5d %5d %5d %5d \" % (amp, acc, sen, ttp, ttn, tfp, tfn) )\n",
    "\n",
    "        plt.plot(TEST_LIST, gsen, label=\"model:%f\"%m)\n",
    "    plt.title(\"Classifier - with shift\")\n",
    "    plt.xlabel(\"Amplitude of injected template\")\n",
    "    plt.ylabel(\"Sensitivity\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###  Testing... with shift\n",
    "###\n",
    "BATCH = 4096\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    test_writer  = tf.summary.FileWriter(ROOT_FOLDER + '/test_hp')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    plt.figure()\n",
    "    for m in TRAIN_A:\n",
    "        try:\n",
    "            load_path = saver.restore(sess, \"%s/model_%4.2f.ckpt\" % (ROOT_FOLDER, m ) )\n",
    "            print(\"Model restored from %s\" % load_path )\n",
    "        except: \n",
    "            continue\n",
    "\n",
    "        gacc=[]\n",
    "        gsen=[]\n",
    "        \n",
    "        for amp in TEST_LIST:\n",
    "            sess.run(tf.local_variables_initializer())\n",
    "            \n",
    "            X_test, Y_test  = GWdata.get_shifted_test_set(A=amp, shift=2500)\n",
    "            randomize = np.arange(len(X_test))\n",
    "            np.random.shuffle(randomize)\n",
    "            X_test = X_test[randomize]\n",
    "            Y_test = Y_test[randomize]\n",
    "            \n",
    "            i=int(np.random.random()* int(len(X_test)/BATCH) )\n",
    "            xbatch = X_test[i*BATCH:(i+1)*BATCH, :]\n",
    "            ybatch = Y_test[i*BATCH:(i+1)*BATCH, :]\n",
    "\n",
    "            acc, sen, ttp, ttn, tfp, tfn = sess.run([accuracy, sensitivity, true_positives, true_negatives, false_positives, false_negatives ], feed_dict={ x: xbatch, y: ybatch })\n",
    "            gsen.append(sen)\n",
    "            gacc.append(acc)\n",
    "            print(\"Test for A= %4.2f : Acc: %9.3f, Sen: %9.3f, TP/TN/FP/FN: %5d %5d %5d %5d \" % (amp, acc, sen, ttp, ttn, tfp, tfn) )\n",
    "\n",
    "        plt.plot(TEST_LIST, gacc, label=\"model:%f\"%m)\n",
    "    plt.title(\"Classifier - with shift\")\n",
    "    plt.xlabel(\"Amplitude of injected template\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
